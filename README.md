
# Video-to-video Sythesis
- Video-to-Video Synthesis  NeurIPS. 2019. [[code](https://github.com/sakshamgupta006/video-to-video-synthesis)]


# Controllable Image Synthesis 
- Controllable Person Image Synthesis with Attribute-Decomposed GAN. CVPR 2020.[[paper](https://arxiv.org/abs/2003.12267)][[code](https://github.com/menyifang/ADGAN)]
- Self-supervised Dance Video Synthesis Conditioned on Music.MM.2020 [[code](https://github.com/xrenaa/Music-Dance-Video-Synthesis)]
- Copy-and-Paste Networks for Deep Video Inpainting ICCV.2019. [[code](https://github.com/shleecs/Copy-and-Paste-Networks-for-Deep-Video-Inpainting)]

# Image Animation
- X2Face: A network for controlling face generation by using images, audio, and pose codes. [[paper](https://arxiv.org/abs/1807.10550)][[code](https://github.com/oawiles/X2Face)][[demo](https://www.robots.ox.ac.uk/~vgg/research/unsup_learn_watch_faces/x2face.html)]
- Monkey-net:Animating Arbitrary Objects via Deep Motion Transfer. CVPR 2019. Oral. [[paper](https://arxiv.org/abs/1812.08861)][[code](https://github.com/AliaksandrSiarohin/monkey-net)]
- First Order Motion Model for Image Animation. NeuIPS. [[paper](https://papers.nips.cc/paper/2019/file/31c0b36aef265d9221af80872ceb62f9-Paper.pdf)][[code](https://github.com/AliaksandrSiarohin/first-order-model)]
- 





# Speech-Driven Animation
- End-to-End Speech-Driven Facial Animation using Temporal GANs [[paper](https://sites.google.com/view/facialsynthesis/home)][[code](https://github.com/DinoMan/speech-driven-animation)]
- Speech2Video Synthesis with 3D Skeleton Regularization and Expressive Body Poses. ACCV 2020. [[paper](https://arxiv.org/abs/2007.09198)][[code](https://github.com/sibozhang/Speech2Video)]


# Game Vedio Sythesis
- https://github.com/thetobysiu/deepstory


# Dataset
- l

